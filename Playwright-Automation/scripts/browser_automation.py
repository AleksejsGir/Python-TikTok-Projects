# -*- coding: utf-8 -*-

"""
Скрипт для автоматизации действий в браузере с использованием Playwright.

Этот скрипт демонстрирует:
- Эмуляцию действий пользователя на веб-сайте (клики, прокрутка, ввод текста)
- Работу с несколькими вкладками (открытие, переключение, закрытие)
- Автоматизацию навигации по сайту (переходы по ссылкам, поиск)
- Работу с прокруткой страницы (скроллинг)

Подобные скрипты могут использоваться для:
- Тестирования веб-сайтов
- Автоматизации повторяющихся действий
- Мониторинга изменений на сайтах
"""

# Импортируем необходимые библиотеки
from playwright.sync_api import sync_playwright  # Основная библиотека для автоматизации
import time  # Для добавления задержек между действиями
import os  # Для работы с файловой системой (создание директорий)


def automate_browser(playwright):
    """
    Основная функция для демонстрации автоматизации действий в браузере.

    Эта функция выполняет последовательность действий на сайте Hacker News:
    - Открывает главную страницу
    - Прокручивает страницу
    - Открывает новость в новой вкладке
    - Выполняет поиск по сайту

    Параметры:
    playwright -- объект Playwright, предоставляющий доступ к браузерам
    """
    # Запускаем браузер с видимым интерфейсом (графическим окном)
    # Для запуска без графического интерфейса установите headless=True
    browser = playwright.chromium.launch(headless=False)

    # Создаем новый браузерный контекст
    # Контекст - это изолированное окружение браузера, что-то вроде отдельного профиля
    # Один браузер может иметь множество контекстов, каждый со своими cookies и хранилищем
    context = browser.new_context()

    # ---- Шаг 1: Открытие сайта ----

    # Создаем новую страницу (вкладку) в нашем контексте
    page = context.new_page()

    # Переходим на сайт Hacker News
    # goto() загружает страницу и автоматически ждет, пока она не будет готова
    page.goto("https://news.ycombinator.com/")

    # Получаем заголовок страницы и выводим его в консоль
    # title() возвращает содержимое тега <title> на странице
    print(f"Заголовок страницы: {page.title()}")

    # ---- Шаг 2: Создание скриншотов ----

    # Создаем директорию для скриншотов, если её нет
    # exist_ok=True означает, что ошибки не будет, если директория уже существует
    os.makedirs("../screenshots", exist_ok=True)

    # Делаем скриншот начальной страницы
    # Скриншот сохраняется в указанный путь относительно текущей директории
    page.screenshot(path="../screenshots/hacker_news_home.png")

    # ---- Шаг 3: Прокрутка страницы ----

    # Эмулируем прокрутку страницы вниз до середины
    # evaluate() позволяет выполнить произвольный JavaScript-код в контексте страницы
    # Здесь мы вызываем window.scrollTo() для прокрутки до половины высоты страницы
    page.evaluate("window.scrollTo(0, document.body.scrollHeight / 2)")

    # Ждем 1 секунду, чтобы увидеть результат прокрутки
    # В реальном скрипте автоматизации лучше использовать явные ожидания,
    # но time.sleep() полезен для демонстрационных целей
    time.sleep(1)

    # Делаем скриншот после прокрутки
    # Это позволяет увидеть, как изменилось видимое содержимое страницы
    page.screenshot(path="../screenshots/hacker_news_scrolled.png")

    # ---- Шаг 4: Взаимодействие с элементами страницы ----

    # Находим все ссылки на новости с помощью CSS-селектора
    # ".titleline > a" означает "найти все теги <a>, которые являются прямыми потомками элементов с классом titleline"
    news_links = page.locator(".titleline > a")

    # Подсчитываем количество найденных ссылок
    count = news_links.count()

    print(f"Найдено {count} новостей")

    # ---- Шаг 5: Работа с несколькими вкладками ----

    # Открываем первую новость в новой вкладке (если новости найдены)
    if count > 0:
        # Получаем первую ссылку из найденных
        # first - это сокращение для nth(0), то есть первого элемента в наборе
        first_news = news_links.first

        # Получаем текст ссылки (заголовок новости)
        title = first_news.inner_text()
        print(f"Открываем новость: {title}")

        # Открываем новость в новой вкладке, удерживая клавишу Ctrl
        # context.expect_page() создает объект ожидания для новой вкладки
        # Внутри блока with мы выполняем действия, которые приведут к открытию новой вкладки
        with context.expect_page() as new_page_info:
            # Имитируем нажатие клавиши Ctrl (для открытия в новой вкладке)
            page.keyboard.down("Control")

            # Кликаем по ссылке
            first_news.click()

            # Отпускаем клавишу Ctrl
            page.keyboard.up("Control")

        # Получаем объект новой страницы (вкладки)
        # value содержит новую страницу, созданную в результате ожидания context.expect_page()
        news_page = new_page_info.value

        # Ожидаем полной загрузки новой страницы
        # wait_for_load_state() ждет, пока страница не достигнет указанного состояния загрузки
        news_page.wait_for_load_state()

        # Делаем скриншот открытой новости
        news_page.screenshot(path="../screenshots/opened_news.png")

        # Закрываем вкладку с новостью
        # close() закрывает страницу и освобождает связанные с ней ресурсы
        news_page.close()

    # ---- Шаг 6: Поиск на сайте ----

    # Возвращаемся на главную страницу Hacker News
    page.goto("https://news.ycombinator.com/")

    # Находим и кликаем по ссылке "Search"
    # a:has-text('Search') - это специальный селектор, означающий "найти тег <a>, содержащий текст 'Search'"
    search_button = page.locator("a:has-text('Search')")
    search_button.click()

    # Ожидаем полной загрузки страницы поиска
    page.wait_for_load_state()

    # Находим поле ввода для поиска и вводим запрос
    search_input = page.locator("input[name='q']")

    # Вводим текст "python" в поле поиска
    search_input.fill("python")

    # Нажимаем Enter для отправки формы поиска
    search_input.press("Enter")

    # Ожидаем загрузки результатов поиска
    page.wait_for_load_state()

    # Делаем скриншот страницы с результатами поиска
    page.screenshot(path="../screenshots/search_results.png")

    print("Автоматизация завершена")

    # Закрываем браузер и освобождаем ресурсы
    browser.close()


# Запускаем наш сценарий автоматизации с Playwright
with sync_playwright() as playwright:
    automate_browser(playwright)

# Советы по автоматизации браузера:
#
# 1. Выбор локаторов (селекторов):
#    - Используйте инструменты разработчика браузера (F12), чтобы найти нужные элементы
#    - Выбирайте стабильные селекторы, которые не меняются при обновлении сайта
#    - Предпочитайте id > data-атрибуты > классы > теги > XPath
#
# 2. Ожидания:
#    - Вместо фиксированных задержек (time.sleep) используйте явные ожидания:
#      * page.wait_for_selector('selector') - ждет появления элемента
#      * page.wait_for_load_state() - ждет загрузки страницы
#      * locator.wait_for() - ждет, пока элемент не станет видимым/доступным
#
# 3. Отладка:
#    - Используйте headless=False для визуального отслеживания действий
#    - Добавляйте page.pause() в критических точках для отладки
#    - Делайте скриншоты для анализа проблем: page.screenshot(path="debug.png")
#
# 4. Обработка ошибок:
#    - Оборачивайте критические операции в try/except блоки
#    - Добавляйте повторные попытки для нестабильных действий
#    - Логируйте ошибки и состояние страницы при их возникновении